{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score\n",
    "import collections\n",
    "import pickle\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/data_provider/data/CriteoSearchData-sorted-no-duplicates-LabelEncoded.csv\"\n",
    "                 ,sep=','\n",
    "                ,nrows=5000000\n",
    "#                 ,skiprows=range(1,2000000)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1, 3.1, 3.1, 2.1, 2.1, 2.1, 2.1, 3.1, 2.1, 2.1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_t = [0,1,1,0,0,0,0,1,0,0]\n",
    "w_array = np.array([1.1]*len(y_t))\n",
    "for id, value in enumerate(y_t):\n",
    "    if value == 0:\n",
    "        w_array[id] = 2.1\n",
    "    else:\n",
    "        w_array[id] = 3.1\n",
    "w_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import f_classif \n",
    "X = df.loc[:,~df.columns.isin(['sale','click_timestamp','sales_amount_in_euro','time_delay_for_conversion','product_price'])]\n",
    "y = df['sale']\n",
    "#apply SelectKBest class to extract top 10 best features\n",
    "bestfeatures = SelectKBest(score_func=f_classif, k=10)\n",
    "fit = bestfeatures.fit(X,y)\n",
    "dfscores = pd.DataFrame(fit.scores_)\n",
    "dfcolumns = pd.DataFrame(X.columns)\n",
    "#concat two dataframes for better visualization \n",
    "featureScores = pd.concat([dfcolumns,dfscores],axis=1)\n",
    "featureScores.columns = ['Specs','Score']  #naming the dataframe columns\n",
    "print(featureScores.nlargest(10,'Score'))  #print 10 best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={'Sale':'sale','SalesAmountInEuro':'sales_amount_in_euro'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_timestamp(df):\n",
    "#     temp = datetime.fromtimestamp(df['click_timestamp'])\n",
    "#     df['year'] = temp.year\n",
    "#     df['month'] = temp.month\n",
    "#     df['day'] = temp.day\n",
    "#     df['hour'] = temp.hour\n",
    "#     return df\n",
    "\n",
    "# df = df.apply(convert_timestamp, axis=1)\n",
    "# df = df.drop(columns=['click_timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names_of_columns_with_ids = ['audience_id', 'device_type',\n",
    "#        'partner_id', 'product_age_group', 'product_brand',\n",
    "#        'product_category_1', 'product_category_2', 'product_category_3',\n",
    "#        'product_category_4', 'product_category_5', 'product_category_6',\n",
    "#        'product_category_7', 'product_country', 'product_gender', 'product_id',\n",
    "#        'product_title', 'user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utworzenia słownika LabelEncoders dla całego zbioru danych\n",
    "# LabelEncoders_dict = collections.defaultdict(LabelEncoder)\n",
    "\n",
    "\n",
    "# df[names_of_columns_with_ids] = df[names_of_columns_with_ids].astype(str)\n",
    "# # Encoding the variable\n",
    "# df[names_of_columns_with_ids] = df[names_of_columns_with_ids].apply(lambda x: LabelEncoders_dict[x.name].fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\n",
    "#     f\"/home/marcin/PycharmProjects/Engineering_Thesis/build_and_update_model_server/LabelEncoders_dict2.pickle\",\n",
    "#     \"wb\")\n",
    "# LabelEncoders_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\n",
    "#     f\"/home/marcin/PycharmProjects/Engineering_Thesis/build_and_update_model_server/LabelEncoders_dict2.pickle\",\n",
    "#     \"rb\")\n",
    "# LabelEncoders_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def first_model(x_train, y_train):\n",
    "#     df[names_of_columns_with_ids] = df[names_of_columns_with_ids].astype(str)\n",
    "#     df[names_of_columns_with_ids] = df[names_of_columns_with_ids].apply(lambda x: LabelEncoders_dict[x.name].transform(x))\n",
    "#     df[names_of_columns_with_ids] = df[names_of_columns_with_ids].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_train, \n",
    "                                                    y_train,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "    number_of_samples = len(y_train)\n",
    "    counter = collections.Counter(y_train)\n",
    "    percent_of_ones = counter[1]/number_of_samples\n",
    "    \n",
    "    w_array = np.array([1.1]*y_train.shape[0])\n",
    "    for id, value in enumerate(y_train):\n",
    "        if value == 0:\n",
    "            w_array[id] = percent_of_ones\n",
    "        else:\n",
    "            w_array[id] = 1-percent_of_ones\n",
    "#     model =  SGDClassifier(loss='log', random_state=1, tol=1e-3, max_iter=1000, penalty='l1', alpha=1e-05, n_jobs=-1, class_weight={0:percent_of_ones, 1:1-percent_of_ones})\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train, sample_weight=w_array)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "\n",
    "    print(collections.Counter(y_test))\n",
    "    print(collections.Counter(y_pred))\n",
    "\n",
    "    print('balanced_accuracy_score: {0}'.format(balanced_accuracy_score(y_test, y_pred)))\n",
    "    print('accuracy_score: {0}'.format(accuracy_score(y_test, y_pred)))\n",
    "    print('Nieprawidłowo sklasyfikowane próbki: %d' % (y_test != y_pred).sum())\n",
    "    print('classification_report :\\n', classification_report(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(confmat)\n",
    "    \n",
    "    return model, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_models(model, df, LabelEncoders_dict, X_test, y_test):\n",
    "    df[names_of_columns_with_ids] = df[names_of_columns_with_ids].astype(str)\n",
    "    df[names_of_columns_with_ids] = df[names_of_columns_with_ids].apply(lambda x: LabelEncoders_dict[x.name].transform(x))\n",
    "    \n",
    "    \n",
    "    model = model.partial_fit(df.loc[:,df.columns != 'sale'], df['sale'])\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(collections.Counter(y_test))\n",
    "    print(collections.Counter(y_pred))\n",
    "\n",
    "    print('balanced_accuracy_score: {0}'.format(balanced_accuracy_score(y_test, y_pred)))\n",
    "    print('accuracy_score: {0}'.format(accuracy_score(y_test, y_pred)))\n",
    "    print('Nieprawidłowo sklasyfikowane próbki: %d' % (y_test != y_pred).sum())\n",
    "    print('classification_report :\\n', classification_report(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(confmat)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 884943, 1: 115057})\n",
      "Counter({0: 611430, 1: 388570})\n",
      "balanced_accuracy_score: 0.6612829532811477\n",
      "accuracy_score: 0.651475\n",
      "Nieprawidłowo sklasyfikowane próbki: 348525\n",
      "classification_report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.65      0.77    884943\n",
      "           1       0.20      0.67      0.31    115057\n",
      "\n",
      "    accuracy                           0.65   1000000\n",
      "   macro avg       0.57      0.66      0.54   1000000\n",
      "weighted avg       0.85      0.65      0.71   1000000\n",
      "\n",
      "[[573924 311019]\n",
      " [ 37506  77551]]\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/build_and_update_model_server/test1.csv\"\n",
    "#                  ,sep=','\n",
    "#                 )\n",
    "# x_train = df.loc[:,~df.columns.isin(['sale','click_timestamp','sales_amount_in_euro','time_delay_for_conversion'])]\n",
    "x_train = df[['device_type','audience_id','partner_id','product_brand','nb_clicks_1week','product_gender','product_age_group']]\n",
    "y_train = df['sale']\n",
    "model, X_test, y_test = first_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/build_and_update_model_server/test2.csv\"\n",
    "                 ,sep=','\n",
    "                )\n",
    "x_train = df.loc[:,~df.columns.isin(['sale'])]\n",
    "y_train = df['sale']\n",
    "model, X_test, y_test = first_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"PIERWSZY MODEL\")\n",
    "x_train = df.loc[:,~df.columns.isin(['sale','sales_amount_in_euro','time_delay_for_conversion','product_price'])]\n",
    "y_train = df['sale']\n",
    "model, X_test, y_test = first_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"PIERWSZY MODEL\")\n",
    "x_train = df.loc[:,~df.columns.isin(['sale'])]\n",
    "y_train = df['sale']\n",
    "model, X_test, y_test = first_model(x_train, y_train)\n",
    "\n",
    "\n",
    "# for i in range(1, 8):\n",
    "#     print(\"=========================================\")\n",
    "#     print(\"MODEL NUMER: \", i+1)\n",
    "#     df2 = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/data_provider/data/CriteoSearchData-sorted-no-duplicates.csv\"\"\n",
    "#                  ,sep='\\t'\n",
    "#                 ,nrows=1000000\n",
    "#                 ,skiprows=range(1, 2000000*i)\n",
    "#                 )\n",
    "#     model = next_models(model, df2, LabelEncoders_dict, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/data_provider/data/CriteoSearchData-sorted-no-duplicates-LabelEncoded.csv\"\n",
    "                 ,sep=','\n",
    "                ,nrows=1000000\n",
    "                ,skiprows=range(1,2000000)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.rename(columns={'Sale':'sale','SalesAmountInEuro':'sales_amount_in_euro'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "s = time.time()\n",
    "for id, row in df[:10000].iterrows():\n",
    "    sample_json = row.to_json()\n",
    "#     s = time.time()\n",
    "    sample_dict = json.loads(sample_json)    \n",
    "    sample_dict_result = sample_dict.copy()\n",
    "    sample_dict.pop('sale', None)\n",
    "    probabilities = model.predict_proba([list(sample_dict.values())])[0].ravel()\n",
    "    if probabilities[0] > probabilities[1]:\n",
    "        sample_dict_result['predicted'] = 0\n",
    "    else:\n",
    "        sample_dict_result['predicted'] = 1\n",
    "        \n",
    "    sample_dict_result['probabilities'] = json.dumps(list(probabilities))\n",
    "#     model.predict([list(sample_dict.values())])\n",
    "\n",
    "#     print(time.time()-s)\n",
    "#     break\n",
    "    \n",
    "print(time.time()-s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/data_provider/data/CriteoSearchData-sorted-no-duplicates.csv\"\n",
    "             ,sep='\\t'\n",
    "             ,nrows=1000\n",
    "            )\n",
    "df2[names_of_columns_with_ids] = df2[names_of_columns_with_ids].astype(str)\n",
    "s2 = time.time()\n",
    "for index, value in LabelEncoders_dict.items():\n",
    "    s = time.time()\n",
    "    LabelEncoders_dict[index].transform(df2[index])\n",
    "    print(index)\n",
    "    print(time.time()-s)\n",
    "print(time.time()-s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_category(7)'] = df['product_category(7)'].astype(str)\n",
    "df['product_title'] = df['product_title'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,6:] = df.iloc[:,6:].apply(LabelEncoder().fit_transform)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,1:], \n",
    "                                                    df['Sale'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(y_train)\n",
    "counter = collections.Counter(y_train)\n",
    "percent_of_ones = counter[1]/number_of_samples\n",
    "percent_of_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  SGDClassifier(loss='log', random_state=1, tol=1e-3, max_iter=1000, penalty='l1', alpha=1e-05, n_jobs=-1)\n",
    "model =  SGDClassifier(loss='log', random_state=1, tol=1e-3, max_iter=1000, penalty='l1', alpha=1e-05, n_jobs=-1, class_weight={0:percent_of_ones, 1:1-percent_of_ones})\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score\n",
    "import collections\n",
    "print(collections.Counter(y_test))\n",
    "print(collections.Counter(y_pred))\n",
    "\n",
    "print('balanced_accuracy_score: {0}'.format(balanced_accuracy_score(y_test, y_pred)))\n",
    "print('accuracy_score: {0}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Nieprawidłowo sklasyfikowane próbki: %d' % (y_test != y_pred).sum())\n",
    "print('classification_report :\\n', classification_report(y_test, y_pred))\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
