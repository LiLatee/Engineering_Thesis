{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score\n",
    "import collections\n",
    "import pickle\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/data_provider/data/CriteoSearchData-sorted-no-duplicates-LabelEncoded.csv\"\n",
    "                 ,sep=','\n",
    "                ,nrows=200000\n",
    "#                 ,skiprows=range(1,2000000)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.rename(columns={'Sale':'sale','SalesAmountInEuro':'sales_amount_in_euro'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def convert_timestamp(df):\n",
    "#     temp = datetime.fromtimestamp(df['click_timestamp'])\n",
    "#     df['year'] = temp.year\n",
    "#     df['month'] = temp.month\n",
    "#     df['day'] = temp.day\n",
    "#     df['hour'] = temp.hour\n",
    "#     return df\n",
    "\n",
    "# df = df.apply(convert_timestamp, axis=1)\n",
    "# df = df.drop(columns=['click_timestamp'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# names_of_columns_with_ids = ['audience_id', 'device_type',\n",
    "#        'partner_id', 'product_age_group', 'product_brand',\n",
    "#        'product_category_1', 'product_category_2', 'product_category_3',\n",
    "#        'product_category_4', 'product_category_5', 'product_category_6',\n",
    "#        'product_category_7', 'product_country', 'product_gender', 'product_id',\n",
    "#        'product_title', 'user_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utworzenia słownika LabelEncoders dla całego zbioru danych\n",
    "# LabelEncoders_dict = collections.defaultdict(LabelEncoder)\n",
    "\n",
    "\n",
    "# df[names_of_columns_with_ids] = df[names_of_columns_with_ids].astype(str)\n",
    "# # Encoding the variable\n",
    "# df[names_of_columns_with_ids] = df[names_of_columns_with_ids].apply(lambda x: LabelEncoders_dict[x.name].fit_transform(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\n",
    "#     f\"/home/marcin/PycharmProjects/Engineering_Thesis/build_and_update_model_server/LabelEncoders_dict2.pickle\",\n",
    "#     \"wb\")\n",
    "# LabelEncoders_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = open(\n",
    "#     f\"/home/marcin/PycharmProjects/Engineering_Thesis/build_and_update_model_server/LabelEncoders_dict2.pickle\",\n",
    "#     \"rb\")\n",
    "# LabelEncoders_dict = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_model(x_train, y_train):\n",
    "#     df[names_of_columns_with_ids] = df[names_of_columns_with_ids].astype(str)\n",
    "#     df[names_of_columns_with_ids] = df[names_of_columns_with_ids].apply(lambda x: LabelEncoders_dict[x.name].transform(x))\n",
    "#     df[names_of_columns_with_ids] = df[names_of_columns_with_ids].apply(LabelEncoder().fit_transform)\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(x_train, \n",
    "                                                    y_train,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)\n",
    "    number_of_samples = len(y_train)\n",
    "    counter = collections.Counter(y_train)\n",
    "    percent_of_ones = counter[1]/number_of_samples\n",
    "\n",
    "    model =  SGDClassifier(loss='log', random_state=1, tol=1e-3, max_iter=1000, penalty='l1', alpha=1e-05, n_jobs=-1, class_weight={0:percent_of_ones, 1:1-percent_of_ones})\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "\n",
    "    print(collections.Counter(y_test))\n",
    "    print(collections.Counter(y_pred))\n",
    "\n",
    "    print('balanced_accuracy_score: {0}'.format(balanced_accuracy_score(y_test, y_pred)))\n",
    "    print('accuracy_score: {0}'.format(accuracy_score(y_test, y_pred)))\n",
    "    print('Nieprawidłowo sklasyfikowane próbki: %d' % (y_test != y_pred).sum())\n",
    "    print('classification_report :\\n', classification_report(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(confmat)\n",
    "    \n",
    "    return model, X_test, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_models(model, df, LabelEncoders_dict, X_test, y_test):\n",
    "    df[names_of_columns_with_ids] = df[names_of_columns_with_ids].astype(str)\n",
    "    df[names_of_columns_with_ids] = df[names_of_columns_with_ids].apply(lambda x: LabelEncoders_dict[x.name].transform(x))\n",
    "    \n",
    "    \n",
    "    model = model.partial_fit(df.loc[:,df.columns != 'sale'], df['sale'])\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    print(collections.Counter(y_test))\n",
    "    print(collections.Counter(y_pred))\n",
    "\n",
    "    print('balanced_accuracy_score: {0}'.format(balanced_accuracy_score(y_test, y_pred)))\n",
    "    print('accuracy_score: {0}'.format(accuracy_score(y_test, y_pred)))\n",
    "    print('Nieprawidłowo sklasyfikowane próbki: %d' % (y_test != y_pred).sum())\n",
    "    print('classification_report :\\n', classification_report(y_test, y_pred))\n",
    "    confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    print(confmat)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIERWSZY MODEL\n",
      "Counter({0: 17535, 1: 2465})\n",
      "Counter({0: 19195, 1: 805})\n",
      "balanced_accuracy_score: 0.6632860040567952\n",
      "accuracy_score: 0.917\n",
      "Nieprawidłowo sklasyfikowane próbki: 1660\n",
      "classification_report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     17535\n",
      "           1       1.00      0.33      0.49      2465\n",
      "\n",
      "    accuracy                           0.92     20000\n",
      "   macro avg       0.96      0.66      0.72     20000\n",
      "weighted avg       0.92      0.92      0.90     20000\n",
      "\n",
      "[[17535     0]\n",
      " [ 1660   805]]\n"
     ]
    }
   ],
   "source": [
    "print(\"PIERWSZY MODEL\")\n",
    "x_train = df.loc[:,~df.columns.isin(['sale'])]\n",
    "y_train = df['sale']\n",
    "model, X_test, y_test = first_model(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIERWSZY MODEL\n",
      "Counter({0: 35038, 1: 4962})\n",
      "Counter({0: 38032, 1: 1968})\n",
      "balanced_accuracy_score: 0.6983071342200725\n",
      "accuracy_score: 0.92515\n",
      "Nieprawidłowo sklasyfikowane próbki: 2994\n",
      "classification_report :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96     35038\n",
      "           1       1.00      0.40      0.57      4962\n",
      "\n",
      "    accuracy                           0.93     40000\n",
      "   macro avg       0.96      0.70      0.76     40000\n",
      "weighted avg       0.93      0.93      0.91     40000\n",
      "\n",
      "[[35038     0]\n",
      " [ 2994  1968]]\n"
     ]
    }
   ],
   "source": [
    "print(\"PIERWSZY MODEL\")\n",
    "x_train = df.loc[:,~df.columns.isin(['sale'])]\n",
    "y_train = df['sale']\n",
    "model, X_test, y_test = first_model(x_train, y_train)\n",
    "\n",
    "\n",
    "# for i in range(1, 8):\n",
    "#     print(\"=========================================\")\n",
    "#     print(\"MODEL NUMER: \", i+1)\n",
    "#     df2 = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/data_provider/data/CriteoSearchData-sorted-no-duplicates.csv\"\"\n",
    "#                  ,sep='\\t'\n",
    "#                 ,nrows=1000000\n",
    "#                 ,skiprows=range(1, 2000000*i)\n",
    "#                 )\n",
    "#     model = next_models(model, df2, LabelEncoders_dict, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/data_provider/data/CriteoSearchData-sorted-no-duplicates-LabelEncoded.csv\"\n",
    "                 ,sep=','\n",
    "                ,nrows=1000000\n",
    "                ,skiprows=range(1,2000000)\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.rename(columns={'Sale':'sale','SalesAmountInEuro':'sales_amount_in_euro'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "s = time.time()\n",
    "for id, row in df[:10000].iterrows():\n",
    "    sample_json = row.to_json()\n",
    "#     s = time.time()\n",
    "    sample_dict = json.loads(sample_json)    \n",
    "    sample_dict_result = sample_dict.copy()\n",
    "    sample_dict.pop('sale', None)\n",
    "    probabilities = model.predict_proba([list(sample_dict.values())])[0].ravel()\n",
    "    if probabilities[0] > probabilities[1]:\n",
    "        sample_dict_result['predicted'] = 0\n",
    "    else:\n",
    "        sample_dict_result['predicted'] = 1\n",
    "        \n",
    "    sample_dict_result['probabilities'] = json.dumps(list(probabilities))\n",
    "#     model.predict([list(sample_dict.values())])\n",
    "\n",
    "#     print(time.time()-s)\n",
    "#     break\n",
    "    \n",
    "print(time.time()-s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(f\"/home/marcin/PycharmProjects/Engineering_Thesis/data_provider/data/CriteoSearchData-sorted-no-duplicates.csv\"\n",
    "             ,sep='\\t'\n",
    "             ,nrows=1000\n",
    "            )\n",
    "df2[names_of_columns_with_ids] = df2[names_of_columns_with_ids].astype(str)\n",
    "s2 = time.time()\n",
    "for index, value in LabelEncoders_dict.items():\n",
    "    s = time.time()\n",
    "    LabelEncoders_dict[index].transform(df2[index])\n",
    "    print(index)\n",
    "    print(time.time()-s)\n",
    "print(time.time()-s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_category(7)'] = df['product_category(7)'].astype(str)\n",
    "df['product_title'] = df['product_title'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[:,6:] = df.iloc[:,6:].apply(LabelEncoder().fit_transform)\n",
    "df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,1:], \n",
    "                                                    df['Sale'],\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_samples = len(y_train)\n",
    "counter = collections.Counter(y_train)\n",
    "percent_of_ones = counter[1]/number_of_samples\n",
    "percent_of_ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =  SGDClassifier(loss='log', random_state=1, tol=1e-3, max_iter=1000, penalty='l1', alpha=1e-05, n_jobs=-1)\n",
    "model =  SGDClassifier(loss='log', random_state=1, tol=1e-3, max_iter=1000, penalty='l1', alpha=1e-05, n_jobs=-1, class_weight={0:percent_of_ones, 1:1-percent_of_ones})\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, balanced_accuracy_score\n",
    "import collections\n",
    "print(collections.Counter(y_test))\n",
    "print(collections.Counter(y_pred))\n",
    "\n",
    "print('balanced_accuracy_score: {0}'.format(balanced_accuracy_score(y_test, y_pred)))\n",
    "print('accuracy_score: {0}'.format(accuracy_score(y_test, y_pred)))\n",
    "print('Nieprawidłowo sklasyfikowane próbki: %d' % (y_test != y_pred).sum())\n",
    "print('classification_report :\\n', classification_report(y_test, y_pred))\n",
    "confmat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "print(confmat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
